{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6635982d",
   "metadata": {},
   "source": [
    "# Libraries used in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0a3fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import posenet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import array\n",
    "import os\n",
    "import argparse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2a6e1f",
   "metadata": {},
   "source": [
    "# Detect pose on the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7213d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BODY_PARTS = { \"Nose\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
    "               \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
    "               \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"REye\": 14,\n",
    "               \"LEye\": 15, \"REar\": 16, \"LEar\": 17, \"Background\": 18 }\n",
    "\n",
    "POSE_PAIRS = [ [\"Neck\", \"RShoulder\"], [\"Neck\", \"LShoulder\"], [\"RShoulder\", \"RElbow\"],\n",
    "               [\"RElbow\", \"RWrist\"], [\"LShoulder\", \"LElbow\"], [\"LElbow\", \"LWrist\"],\n",
    "               [\"Neck\", \"RHip\"], [\"RHip\", \"RKnee\"], [\"RKnee\", \"RAnkle\"], [\"Neck\", \"LHip\"],\n",
    "               [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"], [\"Neck\", \"Nose\"], [\"Nose\", \"REye\"],\n",
    "               [\"REye\", \"REar\"], [\"Nose\", \"LEye\"], [\"LEye\", \"LEar\"] ]\n",
    "\n",
    "width = 368\n",
    "height = 368\n",
    "inWidth = width\n",
    "inHeight = height\n",
    "\n",
    "net = cv.dnn.readNetFromTensorflow(\"graph_opt.pb\")\n",
    "thr = 0.2\n",
    "\n",
    "def poseDetect(frame):\n",
    "    frameWidth = frame.shape[1]\n",
    "    frameHeight = frame.shape[0]\n",
    "    \n",
    "    net.setInput(cv.dnn.blobFromImage(frame, 1.0, (inWidth, inHeight), (127.5, 127.5, 127.5), swapRB=True, crop=False))\n",
    "    out = net.forward()\n",
    "    out = out[:, :19, :, :]  \n",
    "\n",
    "    assert(len(BODY_PARTS) == out.shape[1])\n",
    "\n",
    "    points = []\n",
    "    for i in range(len(BODY_PARTS)):\n",
    "        \n",
    "        heatMap = out[0, i, :, :]\n",
    "\n",
    "        _, conf, _, point = cv.minMaxLoc(heatMap)\n",
    "        x = (frameWidth * point[0]) / out.shape[3]\n",
    "        y = (frameHeight * point[1]) / out.shape[2]\n",
    "        points.append((int(x), int(y)) if conf > thr else None)\n",
    "\n",
    "    for pair in POSE_PAIRS:\n",
    "        partFrom = pair[0]\n",
    "        partTo = pair[1]\n",
    "        assert(partFrom in BODY_PARTS)\n",
    "        assert(partTo in BODY_PARTS)\n",
    "\n",
    "        idFrom = BODY_PARTS[partFrom]\n",
    "        idTo = BODY_PARTS[partTo]\n",
    "\n",
    "        if points[idFrom] and points[idTo]:\n",
    "            cv.line(frame, points[idFrom], points[idTo], (0, 255, 0), 3)\n",
    "            cv.ellipse(frame, points[idFrom], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
    "            cv.ellipse(frame, points[idTo], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
    "\n",
    "    t, _ = net.getPerfProfile()\n",
    "\n",
    "    return frame "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6433be",
   "metadata": {},
   "source": [
    "# Here we can get the labels and features of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754de4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = ['downdog', 'goddess', 'plank', 'tree', 'warrior2']\n",
    "train_feature=[]\n",
    "test_feature=[]\n",
    "train_labels = []\n",
    "test_labels=[]\n",
    "def create_train(DIR,label,feature):\n",
    "    for person in poses:\n",
    "        path = os.path.join(DIR, person)\n",
    "        for img in os.listdir(path):\n",
    "            img_path = os.path.join(path,img)\n",
    "            img_array = cv.imread(img_path)\n",
    "            if img_array is None:\n",
    "                continue \n",
    "            else:\n",
    "                frame = poseDetect(img_array)\n",
    "                frame_new=cv.imread(img_path)\n",
    "                if(frame.shape[2]==frame_new.shape[2]):\n",
    "                    frame_diff=frame-frame_new\n",
    "                    feature.append(frame_diff)\n",
    "                    label.append(person)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b3dc81",
   "metadata": {},
   "source": [
    "# For Train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01331b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose=create_train(r\"C:\\Users\\ankit\\Documents\\Python Scripts\\Face Recognition\\Intern Project\\Yoga Train Pose\",train_labels,train_feature)\n",
    "features_train=np.array(train_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154bcb99",
   "metadata": {},
   "source": [
    "# For Test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf75fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pose = create_train(r\"C:\\Users\\ankit\\Documents\\Python Scripts\\Face Recognition\\Intern Project\\Yoga Test Pose\",test_labels,test_feature)\n",
    "features_test=np.array(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710940c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train.reshape(len(train_labels),1)\n",
    "features_test.reshape(len(test_labels),1)\n",
    "\n",
    "train_data=pd.DataFrame(features_train ,columns=['tr_feature'])\n",
    "train_labels_data=pd.DataFrame(train_labels ,columns=['tr_label'])\n",
    "\n",
    "test_data=pd.DataFrame(features_test ,columns=['te_feature'])\n",
    "test_labels_data=pd.DataFrame(test_labels ,columns=['te_label'])\n",
    "\n",
    "for i in range(len(train_data['tr_feature'])):\n",
    "    train_data['tr_feature'][i]=train_data['tr_feature'][i].flatten()\n",
    "for i in range(len(test_data['te_feature'])):\n",
    "    test_data['te_feature'][i]=test_data['te_feature'][i].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155581e7",
   "metadata": {},
   "source": [
    "# LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8113e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label=LabelEncoder()\n",
    "labels_train=label.fit_transform(train_labels_data['tr_label'])\n",
    "labels_test=label.fit_transform(test_labels_data['te_label']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76dd42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=[]\n",
    "test=[]\n",
    "for i in range(len(train_data['tr_feature'])):\n",
    "     train.append(train_data ['tr_feature'][i].std())\n",
    "for i in range(len(test_data['te_feature'])):\n",
    "     test.append(test_data['te_feature'][i].std())\n",
    "        \n",
    "train=np.array(train)\n",
    "train=np.reshape(train,(len(labels_train),1))\n",
    "test=np.array(test)\n",
    "test=np.reshape(test,(len(labels_test),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c30808",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28c0d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc=RandomForestClassifier(n_estimators=300,criterion='entropy',\n",
    "                             max_features='sqrt',min_samples_leaf=10,random_state=100)\n",
    "rfc.fit(train,labels_train)\n",
    "predict=rfc.predict(test)\n",
    "print(classification_report(labels_test,predict))\n",
    "print(confusion_matrix(labels_test,predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb77e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(train,labels_train)\n",
    "predict=rfc.predict(train)\n",
    "print(classification_report(labels_train,predict))\n",
    "print(confusion_matrix(labels_train,predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d276f191",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d38144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(train,labels_train)\n",
    "predict_knn=knn.predict(test)\n",
    "print(classification_report(labels_test,predict_knn))\n",
    "print(confusion_matrix(labels_test,predict_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168c42ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(train,labels_train)\n",
    "predict_rfc=knn.predict(train)\n",
    "print(classification_report(labels_train,predict_rfc))\n",
    "print(confusion_matrix(labels_train,predict_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b564ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cd7919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
